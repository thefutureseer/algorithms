
~Runtime compexity~ 
(usually the same as space complexity)

NOTE on Big O:
Big O() notation folder breaks down a more concrete way to compare algorithms. The letter o is used because
the rate of growth of a function is also called "ORDER OF THE FUNCTION".

Goal of this Big(O) folder: The ability to identify runtime complexity.

   "Describe the performance of an algorithm" -H.T.

THE BIG QUESTION:
*) How much more PROCESSING POWER/TIME is required to run your algorithm if we
DOUBLE THE INPUTS.

BREIF STORY: "How to save a million dollars", highlighting an "exponential" growth pattern.
As a child growing up in Oakland, California a teacher of mine said something that stuck with me and motivated
me. He said, "Do you want to know how to save a million dollars? If you want to save money, just try saving 
or 30 days straight. Save one penny on the first day and the second day save double so now you have 3 cents, 
right? Then the 3 day you double it again and everyday after that you do the same thing, you take the amount
you have and double it. You do that for 30 days straight and you will have over one million dollars in your
savings!". 

Note: The first algorithm may not be the most efficient but the fastest to code, assuming it will be replaced
with a more efficient one in a later version. I.E. Common in agile divelopment, esp Test driven development.

COMMON RUNTIMES used to identify many different algorithms:

n = input size

CONSTANT time/"Order 1"/ = 1 or Seen as: O(1).
      No matter how many elements we are working with the algorithm/operation/whatever
      will always take the same amount of time. Its bound by a value not by the inputs.
      You will see this on algorithms that return an element in an already known position of an
      array regardless of kind or length.
 I.E. 
   1) The function GETFIRSTVALUE() because it always returns the first value.
   2) Variable doesnt do anything exept hold an integer = O(1).
        Also the adding of the integer in that variable to another integer = O(1).
   3) Including a function returning that variable value = O(1) as long 
        as the number can fit into a single integer variable.

 Story to remember it: Like a big giant ferris wheel with all the bright lights, it starts goes for 10 minutes 
                       and stops for 5 minutes and goes for 10 min, stops for ten min. It never matters how 
                       many extra people are on it. The time never changes so it's runtime is seen as
                       constant time.

LOGARITHMIC time/ = log(n)
         "DOUBLING the number of elements you are iterating over does NOT 
          double the amount of work."
  I.E.
    1) Usually in a search of an array (which is after the array is sorted).
    2) More complex than constants but not as complex as polynomials

  NOTE: Always assume search operations are log(n)

  Story to remember it: In jr. high school everybody was forced to take a choir class because we had a famous
                        teacher who the school was able to workout a deal with. In choir class we all had 
                        a number so we knew exactly where to stand for the big show. Every child knew their 
                        number if asked that person could scream it out. It doesn't matter how many students 
                        would be in attendence it never took extra work for the choir teacher to ask any one 
                        what their number is.